# Haykin NN (Drive)

## 3. LMS
### 3.3 Unconstrained Optimization


LMS, being stochastic, has optimal solution that wanders around a small region.
Analogical to a particle in a system with heat and random dynamics (think brownian motion and 'Langevin' dynamics)


### 10.14 Natural Gradient

### 11.7 Boltzmann Machine

...

1. Positive Phase
2. Negative Phase

Call x the observed samples in one instance, X the full training data.
Call observed samples xa, a subset of variables in x.
Training set examples are iid, so p(Xa = xa) is factorial distribution (product)
log-liklihood is thus a sum of log p


Push up on positive samples
Push down on all samples
End result: positive samples higher

Gibbs Sampling is a means to draw these positive samples.

pg. 603


### 11.10 Deterministic Annealing

...

_Equivalent to EM_

## 14. Bayesian Filtering
State-Space Model. Can view state-estimation is an inverse problem.


